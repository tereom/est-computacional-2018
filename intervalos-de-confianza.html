<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>6.3 Intervalos de confianza | Estadística Computacional</title>
  <meta name="description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="6.3 Intervalos de confianza | Estadística Computacional" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  <meta name="github-repo" content="tereom/est-computacional-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.3 Intervalos de confianza | Estadística Computacional" />
  
  <meta name="twitter:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  

<meta name="author" content="María Teresa Ortiz">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="el-estimador-bootstrap-del-error-estandar.html">
<link rel="next" href="bootstrap-en-r.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/d3-3.5.6/d3.min.js"></script>
<link href="libs/profvis-0.3.5/profvis.css" rel="stylesheet" />
<script src="libs/profvis-0.3.5/profvis.js"></script>
<link href="libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="libs/highlight-6.2.0/highlight.js"></script>
<script src="libs/profvis-binding-0.3.5/profvis.js"></script>
<script src="libs/plotly-binding-4.8.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.39.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.39.2/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
<link rel="stylesheet" href="css/font-awesome.min.css" type="text/css" />
<link rel="stylesheet" href="css/cajas.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Computacional</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html"><i class="fa fa-check"></i>Temario</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#calificacion"><i class="fa fa-check"></i>Calificación</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#otros-recursos"><i class="fa fa-check"></i>Otros recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html"><i class="fa fa-check"></i><b>1</b> Introducción a visualización</a><ul>
<li class="chapter" data-level="" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html#el-cuarteto-de-ascombe"><i class="fa fa-check"></i>El cuarteto de Ascombe</a></li>
<li class="chapter" data-level="1.1" data-path="introduccion.html"><a href="introduccion.html"><i class="fa fa-check"></i><b>1.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-de-datos-en-la-estadistica"><i class="fa fa-check"></i>Visualización de datos en la estadística</a></li>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>1.2</b> Teoría de visualización de datos</a><ul>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#principios-generales-del-diseno-analitico"><i class="fa fa-check"></i>Principios generales del diseño analítico</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tecnicas-de-visualizacion"><i class="fa fa-check"></i>Técnicas de visualización</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#indicadores-de-calidad-grafica"><i class="fa fa-check"></i>Indicadores de calidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#factor-de-engano-chartjunk-y-pies"><i class="fa fa-check"></i>Factor de engaño, chartjunk y pies</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#series-de-tiempo-y-promedio-de-45"><i class="fa fa-check"></i>Series de tiempo y promedio de 45</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#pequenos-multiplos-y-densidad-grafica"><i class="fa fa-check"></i>Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tinta-de-datos"><i class="fa fa-check"></i>Tinta de datos</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#percepcion-de-escala"><i class="fa fa-check"></i>Percepción de escala</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#minard"><i class="fa fa-check"></i>Minard</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduccion-a-r-y-al-paquete-ggplot2.html"><a href="introduccion-a-r-y-al-paquete-ggplot2.html"><i class="fa fa-check"></i><b>2</b> Introducción a R y al paquete ggplot2</a><ul>
<li class="chapter" data-level="2.1" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html"><i class="fa fa-check"></i><b>2.1</b> R: primeros pasos</a><ul>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#r-en-analisis-de-datos"><i class="fa fa-check"></i>R en análisis de datos</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#paquetes-y-el-tidyverse"><i class="fa fa-check"></i>Paquetes y el Tidyverse</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#recursos"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html"><i class="fa fa-check"></i><b>2.2</b> Visualización con ggplot2</a><ul>
<li class="chapter" data-level="" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html#recursos-1"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-agrupacion-de-datos.html"><a href="manipulacion-y-agrupacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y agrupación de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html"><i class="fa fa-check"></i><b>3.1</b> Transformación de datos</a><ul>
<li><a href="transformacion-de-datos.html#separa-aplica-combina-split-apply-combine">Separa-aplica-combina (<em>split-apply-combine</em>)</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ejemplos-y-lectura-de-datos"><i class="fa fa-check"></i>Ejemplos y lectura de datos</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#filtrar"><i class="fa fa-check"></i>Filtrar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#seleccionar"><i class="fa fa-check"></i>Seleccionar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ordenar"><i class="fa fa-check"></i>Ordenar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#mutar"><i class="fa fa-check"></i>Mutar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#summarise-y-resumenes-por-grupo"><i class="fa fa-check"></i>Summarise y resúmenes por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#operador-pipeline"><i class="fa fa-check"></i>Operador pipeline</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#variables-por-grupo"><i class="fa fa-check"></i>Variables por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#verbos-de-dos-tablas"><i class="fa fa-check"></i>Verbos de dos tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="datos-limpios.html"><a href="datos-limpios.html"><i class="fa fa-check"></i><b>3.2</b> Datos limpios</a><ul>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#limpieza-bases-de-datos"><i class="fa fa-check"></i>Limpieza bases de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#los-encabezados-de-las-columanas-son-valores"><i class="fa fa-check"></i>Los encabezados de las columanas son valores</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-columna-asociada-a-mas-de-una-variable"><i class="fa fa-check"></i>Una columna asociada a más de una variable</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#variables-almacenadas-en-filas-y-columnas"><i class="fa fa-check"></i>Variables almacenadas en filas y columnas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#mas-de-un-tipo-de-observacion-en-una-misma-tabla"><i class="fa fa-check"></i>Mas de un tipo de observación en una misma tabla</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-misma-unidad-observacional-esta-almacenada-en-multiples-tablas"><i class="fa fa-check"></i>Una misma unidad observacional está almacenada en múltiples tablas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#otras-consideraciones"><i class="fa fa-check"></i>Otras consideraciones</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#recursos-adicionales"><i class="fa fa-check"></i>Recursos adicionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="temas-selectos-de-r.html"><a href="temas-selectos-de-r.html"><i class="fa fa-check"></i><b>4</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="4.1" data-path="funciones.html"><a href="funciones.html"><i class="fa fa-check"></i><b>4.1</b> Funciones</a><ul>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#estructura-de-una-funcion"><i class="fa fa-check"></i>Estructura de una función</a></li>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#observaciones-del-uso-de-funciones"><i class="fa fa-check"></i>Observaciones del uso de funciones</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="vectores.html"><a href="vectores.html"><i class="fa fa-check"></i><b>4.2</b> Vectores</a><ul>
<li class="chapter" data-level="" data-path="vectores.html"><a href="vectores.html#propiedades"><i class="fa fa-check"></i>Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="iteracion.html"><a href="iteracion.html"><i class="fa fa-check"></i><b>4.3</b> Iteración</a></li>
<li class="chapter" data-level="4.4" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html"><i class="fa fa-check"></i><b>4.4</b> Rendimiento en R</a><ul>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#diagnosticar"><i class="fa fa-check"></i>Diagnosticar</a></li>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#estrategias-para-mejorar-desempeno"><i class="fa fa-check"></i>Estrategias para mejorar desempeño</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduccion-a-probabilidad.html"><a href="introduccion-a-probabilidad.html"><i class="fa fa-check"></i><b>5</b> Introducción a probabilidad</a><ul>
<li class="chapter" data-level="5.1" data-path="probabilidad-como-extension-a-proporcion.html"><a href="probabilidad-como-extension-a-proporcion.html"><i class="fa fa-check"></i><b>5.1</b> Probabilidad como extensión a proporción</a></li>
<li class="chapter" data-level="5.2" data-path="interpretacion-frecuentista-de-probabilidad.html"><a href="interpretacion-frecuentista-de-probabilidad.html"><i class="fa fa-check"></i><b>5.2</b> Interpretación frecuentista de probabilidad</a></li>
<li class="chapter" data-level="5.3" data-path="simulacion-para-el-calculo-de-probabilidades.html"><a href="simulacion-para-el-calculo-de-probabilidades.html"><i class="fa fa-check"></i><b>5.3</b> Simulación para el cálculo de probabilidades</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html"><i class="fa fa-check"></i><b>5.4</b> Probabilidad: definición matemática</a><ul>
<li class="chapter" data-level="5.4.1" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html#propiedades-de-la-funcion-de-probabilidad"><i class="fa fa-check"></i><b>5.4.1</b> Propiedades de la función de probabilidad:</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>5.5</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bootstrap-no-parametrico.html"><a href="bootstrap-no-parametrico.html"><i class="fa fa-check"></i><b>6</b> Bootstrap no paramétrico</a><ul>
<li class="chapter" data-level="6.1" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html"><i class="fa fa-check"></i><b>6.1</b> El principio del plug-in</a><ul>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#muestras-aleatorias"><i class="fa fa-check"></i>Muestras aleatorias</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#funcion-de-distribucion-empirica"><i class="fa fa-check"></i>Función de distribución empírica</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#parametros-y-estadisticas"><i class="fa fa-check"></i>Parámetros y estadísticas</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#distribuciones-muestrales-y-errores-estandar"><i class="fa fa-check"></i>Distribuciones muestrales y errores estándar</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html"><i class="fa fa-check"></i><b>6.2</b> El estimador bootstrap del error estándar</a><ul>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#variacion-en-distribuciones-bootstrap"><i class="fa fa-check"></i>Variación en distribuciones bootstrap</a></li>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#mas-alla-de-muestras-aleatorias-simples"><i class="fa fa-check"></i>Más alla de muestras aleatorias simples</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>6.3</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="6.4" data-path="bootstrap-en-r.html"><a href="bootstrap-en-r.html"><i class="fa fa-check"></i><b>6.4</b> Bootstrap en R</a></li>
<li class="chapter" data-level="6.5" data-path="conclusiones-y-observaciones.html"><a href="conclusiones-y-observaciones.html"><i class="fa fa-check"></i><b>6.5</b> Conclusiones y observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="teoria-basica-de-simulacion.html"><a href="teoria-basica-de-simulacion.html"><i class="fa fa-check"></i><b>7</b> Teoría básica de simulación</a><ul>
<li class="chapter" data-level="7.1" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html"><i class="fa fa-check"></i><b>7.1</b> Números pseudoaleatorios</a><ul>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#generadores-congruenciales-y-mersenne-twister"><i class="fa fa-check"></i>Generadores congruenciales y Mersenne-Twister</a></li>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#pruebas-de-aleatoriedad"><i class="fa fa-check"></i>Pruebas de aleatoriedad</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html"><i class="fa fa-check"></i><b>7.2</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-discretas-importantes"><i class="fa fa-check"></i>Familias discretas importantes</a></li>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-continuas-importantes"><i class="fa fa-check"></i>Familias Continuas importantes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html"><i class="fa fa-check"></i><b>7.3</b> Simulación de variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aletaorias-discretas"><i class="fa fa-check"></i>Variables aletaorias discretas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i>Variables aleatorias continuas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo-1"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html"><i class="fa fa-check"></i><b>8</b> Simulación de modelos</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html#para-que-simular-de-un-modelo"><i class="fa fa-check"></i>¿Para qué simular de un modelo?</a></li>
<li class="chapter" data-level="8.1" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html"><i class="fa fa-check"></i><b>8.1</b> Distribuciones multivariadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#regla-de-bayes"><i class="fa fa-check"></i>Regla de Bayes</a></li>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#independencia"><i class="fa fa-check"></i>Independencia</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-graficos-y-simulacion-predictiva.html"><a href="modelos-graficos-y-simulacion-predictiva.html"><i class="fa fa-check"></i><b>8.2</b> Modelos gráficos y simulación predictiva</a></li>
<li class="chapter" data-level="8.3" data-path="inferencia-visual.html"><a href="inferencia-visual.html"><i class="fa fa-check"></i><b>8.3</b> Inferencia visual</a><ul>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia"><i class="fa fa-check"></i>Inferencia</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#protocolos-de-inferencia-visual"><i class="fa fa-check"></i>Protocolos de inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#pruebas-de-hipotesis-tipicas"><i class="fa fa-check"></i>Pruebas de hipótesis típicas</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia-visual-1"><i class="fa fa-check"></i>Inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#mas-alla-que-permutacion"><i class="fa fa-check"></i>Más allá que permutación</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#otras-consideraciones-1"><i class="fa fa-check"></i>Otras consideraciones</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><a href="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><i class="fa fa-check"></i><b>8.4</b> Simulación para cálculo de tamaño de muestra/poder estadístico</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inferencia-parametrica.html"><a href="inferencia-parametrica.html"><i class="fa fa-check"></i><b>9</b> Inferencia paramétrica</a><ul>
<li class="chapter" data-level="9.1" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html"><i class="fa fa-check"></i><b>9.1</b> Máxima verosimilitud</a><ul>
<li class="chapter" data-level="" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html#propiedades-de-los-estimadores-de-maxima-verosimilitud"><i class="fa fa-check"></i>Propiedades de los estimadores de máxima verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="bootstrap-parametrico.html"><a href="bootstrap-parametrico.html"><i class="fa fa-check"></i><b>9.2</b> Bootstrap paramétrico</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="analisis-bayesiano.html"><a href="analisis-bayesiano.html"><i class="fa fa-check"></i><b>10</b> Análisis bayesiano</a><ul>
<li class="chapter" data-level="10.1" data-path="probabilidad-subjetiva.html"><a href="probabilidad-subjetiva.html"><i class="fa fa-check"></i><b>10.1</b> Probabilidad subjetiva</a></li>
<li class="chapter" data-level="10.2" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html"><i class="fa fa-check"></i><b>10.2</b> Regla de Bayes e inferencia bayesiana</a><ul>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#regla-de-bayes-en-modelos-y-datos"><i class="fa fa-check"></i>Regla de Bayes en modelos y datos</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#objetivos-de-la-inferencia"><i class="fa fa-check"></i>Objetivos de la inferencia</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#calculo-de-la-distribucion-posterior"><i class="fa fa-check"></i>Cálculo de la distribución posterior</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html"><i class="fa fa-check"></i><b>10.3</b> Distribuciones conjugadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html#ejemplo-bernoulli"><i class="fa fa-check"></i>Ejemplo: Bernoulli</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="aproximacion-por-cuadricula.html"><a href="aproximacion-por-cuadricula.html"><i class="fa fa-check"></i><b>10.4</b> Aproximación por cuadrícula</a></li>
<li class="chapter" data-level="10.5" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>10.5</b> MCMC</a><ul>
<li class="chapter" data-level="" data-path="mcmc.html"><a href="mcmc.html#introduccion-metropolis"><i class="fa fa-check"></i>Introducción Metrópolis</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="metropolis.html"><a href="metropolis.html"><i class="fa fa-check"></i><b>10.6</b> Metrópolis</a><ul>
<li class="chapter" data-level="" data-path="metropolis.html"><a href="metropolis.html#inferencia-de-dos-proporciones-binomiales"><i class="fa fa-check"></i>Inferencia de dos proporciones binomiales</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html"><i class="fa fa-check"></i><b>10.7</b> Muestreador de Gibbs</a><ul>
<li class="chapter" data-level="" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html#conclusiones-y-observaciones-metropolis-y-gibbs"><i class="fa fa-check"></i>Conclusiones y observaciones Metrópolis y Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="jags.html"><a href="jags.html"><i class="fa fa-check"></i><b>10.8</b> JAGS</a><ul>
<li class="chapter" data-level="" data-path="jags.html"><a href="jags.html#ejemplo-normal-1"><i class="fa fa-check"></i>Ejemplo normal</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="diagnosticos.html"><a href="diagnosticos.html"><i class="fa fa-check"></i><b>10.9</b> Diagnósticos</a><ul>
<li class="chapter" data-level="" data-path="diagnosticos.html"><a href="diagnosticos.html#recomendaciones-generales"><i class="fa fa-check"></i>Recomendaciones generales</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html"><i class="fa fa-check"></i><b>10.10</b> HMC y Stan</a><ul>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#muestreo-hmc"><i class="fa fa-check"></i>Muestreo HMC</a></li>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#iniciales"><i class="fa fa-check"></i>Iniciales</a></li>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#recursos-adicionales-de-stan"><i class="fa fa-check"></i>Recursos adicionales de Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html"><i class="fa fa-check"></i><b>10.11</b> Modelos jerárquicos</a><ul>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#modelo-jerarquico-una-moneda"><i class="fa fa-check"></i>Modelo jerárquico una moneda</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#multiples-monedas-de-una-misma-fabrica"><i class="fa fa-check"></i>Multiples monedas de una misma fábrica</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#ejemplo-estimacion-de-tasas-de-mortalidad"><i class="fa fa-check"></i>Ejemplo: estimación de tasas de mortalidad</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#ejemplo-conteo-rapido"><i class="fa fa-check"></i>Ejemplo: conteo rápido</a></li>
</ul></li>
<li class="chapter" data-level="10.12" data-path="flujo-de-trabajo-para-el-analisis-bayesiano.html"><a href="flujo-de-trabajo-para-el-analisis-bayesiano.html"><i class="fa fa-check"></i><b>10.12</b> Flujo de trabajo para el análisis bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a><ul>
<li class="chapter" data-level="" data-path="transformacion-de-datos-1.html"><a href="transformacion-de-datos-1.html"><i class="fa fa-check"></i>2-Transformación de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios-1.html"><a href="datos-limpios-1.html"><i class="fa fa-check"></i>3-Datos Limpios</a></li>
<li class="chapter" data-level="" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i>4-Probabilidad</a></li>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i>5-Bootstrap</a><ul>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html#solucion"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html"><i class="fa fa-check"></i>6-Cobertura de intervalos de confianza</a><ul>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html#solucion-1"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-1.html"><a href="simulacion-de-modelos-1.html"><i class="fa fa-check"></i>7-Simulación de modelos</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-de-regresion.html"><a href="simulacion-de-modelos-de-regresion.html"><i class="fa fa-check"></i>8-Simulación de modelos de regresión</a></li>
<li class="chapter" data-level="" data-path="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><a href="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><i class="fa fa-check"></i>9-Inferencia gráfica, tamaño de muestra, bootstrap paramétrico.</a><ul>
<li class="chapter" data-level="" data-path="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><a href="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html#solucion-2"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="familias-conjugadas.html"><a href="familias-conjugadas.html"><i class="fa fa-check"></i>10-Familias conjugadas</a></li>
<li class="chapter" data-level="" data-path="metropolis-2.html"><a href="metropolis-2.html"><i class="fa fa-check"></i>11-Metropolis</a><ul>
<li class="chapter" data-level="" data-path="metropolis-2.html"><a href="metropolis-2.html#solucion-3"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="mcmc-convergencia.html"><a href="mcmc-convergencia.html"><i class="fa fa-check"></i>12-MCMC convergencia</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html"><i class="fa fa-check"></i>13-Modelos jerárquicos</a></li>
<li class="chapter" data-level="" data-path="ejercicios-clase-modelos-jerarquicos.html"><a href="ejercicios-clase-modelos-jerarquicos.html"><i class="fa fa-check"></i>14-Ejercicios clase modelos jerárquicos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intervalos-de-confianza" class="section level2">
<h2><span class="header-section-number">6.3</span> Intervalos de confianza</h2>
<p>Hasta ahora hemos discutido la idea detrás del bootstrap y como se puede usar
para estimar errores estándar. Comenzamos con el error estándar pues es la
manera más común para describir la precisión de una estadística.</p>
<ul>
<li><p>En términos generales, esperamos que <span class="math inline">\(\bar{x}\)</span> este a una distancia de <span class="math inline">\(\mu_P\)</span>
menor a un error estándar el 68% del tiempo, y a menos de 2 errores estándar el
95% del tiempo.</p></li>
<li><p>Estos porcentajes están basados el teorema central del límite que nos dice que
bajo ciertas condiciones (bastante generales) de <span class="math inline">\(P\)</span> la distribución de
<span class="math inline">\(\bar{x}\)</span> se aproximará a una distribución normal:</p></li>
</ul>
<p><span class="math display">\[\bar{x} \overset{\cdot}{\sim} N(\mu_P,\sigma_P^2/n)\]</span></p>
<p>Veamos algunos ejemplos de como funciona el Teorema del Límite
Central, buscamos ver como se aproxima la distribución muestral de la media
(cuando las observaciones provienen de distintas distribuciones) a una
Normal conforme aumenta el tamaño de muestra. Para esto, aproximamos la
distribución muestral de la media usando simulación de la población.</p>
<p>Vale la pena observar que hay distribuciones que requieren un mayor tamaño
de muestra <span class="math inline">\(n\)</span> para lograr una buena aproximación (por ejemplo la log-normal),
¿a qué se debe esto?</p>
<p>Para la opción de <em>Elecciones</em> tenemos una población de tamaño <span class="math inline">\(N=143,437\)</span> y el
objetivo es estimar la media del tamaño de la lista nominal de las casillas
(datos de las elecciones presidenciales de 2012). Podemos ver como mejora la
aproximación Normal de la distribución muestral conforme aumenta el tamaño de
muestra <span class="math inline">\(n\)</span>; sin embargo, también sobresale que no es necesario tomar una
muestra demasiado grande (<span class="math inline">\(n = 60\)</span> ya es razonable).</p>
<pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">include_app</span>(<span class="st">&quot;https://tereom.shinyapps.io/15-TLC/&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;900px&quot;</span>)</code></pre>
<iframe src="https://tereom.shinyapps.io/15-TLC/?showcase=0" width="672" height="900px">
</iframe>
<p>En lo que sigue veremos distintas maneras de construir intervalos de confianza
usando bootstrap.</p>
<div class="caja">
<p>Un <strong>intervalo de confianza</strong> <span class="math inline">\((1-2\alpha)\)</span>% para un parámetro <span class="math inline">\(\theta\)</span> es un
intervalo <span class="math inline">\((a,b)\)</span> tal que <span class="math inline">\(P(a \le \theta \le b) = 1-2\alpha\)</span> para todo
<span class="math inline">\(\theta \in \Theta\)</span>.</p>
</div>
<p>Y comenzamos con la versión bootstrap del intervalo más popular.</p>
<div class="caja">
<ol style="list-style-type: decimal">
<li><strong>Intervalo Normal</strong> con error estándar bootstrap.
El intervalo para <span class="math inline">\(\hat{\theta}\)</span> con un nivel de confianza de
<span class="math inline">\(100\cdot(1-2\alpha)\%\)</span> se define como:</li>
</ol>
<p><span class="math display">\[(\hat{\theta}-z^{(1-\alpha)}\cdot \hat{se}_B, \hat{\theta}+z^{(1-\alpha)}\cdot \hat{se})\]</span>.</p>
<p>donde <span class="math inline">\(z^{(\alpha)}\)</span> denota el percentil <span class="math inline">\(100\cdot \alpha\)</span> de una
distribución <span class="math inline">\(N(0,1)\)</span>.</p>
</div>
<p>este intervalo está soportado por el Teorema Central del Límite, sin embargo,
no es adecuado cuando <span class="math inline">\(\hat{\theta}\)</span> no se distribuye aproximadamente Normal.</p>
<div id="ejemplo-kurtosis" class="section level4 unnumbered">
<h4>Ejemplo: kurtosis</h4>
<p>Supongamos que queremos estimar la kurtosis de una base de datos que consta de
799 tiempos de espera entre pulsasiones de un nervio (Cox, Lewis 1976).</p>
<p><span class="math display">\[\hat{\theta} = t(P_n) =\frac{1/n \sum_{i=1}^n(x_i-\hat{\mu})^3}{\hat{\sigma}^3}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">nerve &lt;-<span class="st"> </span><span class="kw">read_delim</span>(<span class="st">&quot;data/nerve.txt&quot;</span>, <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">escape_double =</span> <span class="ot">FALSE</span>, 
    <span class="dt">col_names =</span> <span class="ot">FALSE</span>, <span class="dt">trim_ws =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; Parsed with column specification:</span>
<span class="co">#&gt; cols(</span>
<span class="co">#&gt;   X1 = col_double(),</span>
<span class="co">#&gt;   X2 = col_double(),</span>
<span class="co">#&gt;   X3 = col_double(),</span>
<span class="co">#&gt;   X4 = col_double(),</span>
<span class="co">#&gt;   X5 = col_double(),</span>
<span class="co">#&gt;   X6 = col_double()</span>
<span class="co">#&gt; )</span>
nerve_long &lt;-<span class="st"> </span>tidyr<span class="op">::</span><span class="kw">gather</span>(nerve, col, val, X1<span class="op">:</span>X6) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(val))

kurtosis &lt;-<span class="st"> </span><span class="cf">function</span>(x){
    n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
    <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>n <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)) <span class="op">^</span><span class="st"> </span><span class="dv">3</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(x) <span class="op">^</span><span class="st"> </span><span class="dv">3</span> 
}

theta_hat &lt;-<span class="st"> </span><span class="kw">kurtosis</span>(nerve_long<span class="op">$</span>val)
theta_hat
<span class="co">#&gt; [1] 1.7579</span>

kurtosis_boot &lt;-<span class="st"> </span><span class="cf">function</span>(x, n){
  x_boot &lt;-<span class="st"> </span><span class="kw">sample</span>(x, n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
  <span class="kw">kurtosis</span>(x_boot)
}
B &lt;-<span class="st"> </span><span class="dv">10000</span>
kurtosis &lt;-<span class="st"> </span><span class="kw">rerun</span>(B, <span class="kw">kurtosis_boot</span>(nerve_long<span class="op">$</span>val, <span class="kw">length</span>(nerve_long<span class="op">$</span>val))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">flatten_dbl</span>()</code></pre>
<p>Usando el intervalo normal tenemos:</p>
<pre class="sourceCode r"><code class="sourceCode r">li_normal &lt;-<span class="st"> </span><span class="kw">round</span>(theta_hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(kurtosis), <span class="dv">2</span>)
ls_normal &lt;-<span class="st"> </span><span class="kw">round</span>(theta_hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(kurtosis), <span class="dv">2</span>)
<span class="kw">c</span>(li_normal, ls_normal)
<span class="co">#&gt; [1] 1.44 2.08</span></code></pre>
<p>Una modificación común del intervalo normal es el intervalo t, estos intervalos
son mejores en caso de muestras pequeñas (<span class="math inline">\(n\)</span> chica).</p>
<div class="caja">
<ol start="2" style="list-style-type: decimal">
<li><strong>Intervalo <span class="math inline">\(t\)</span></strong> con error estándar bootstrap. Para una muestra de tamaño
<span class="math inline">\(n\)</span> el intervalo <span class="math inline">\(t\)</span> con un nivel de confianza de <span class="math inline">\(100\cdot(1-2\alpha)\%\)</span> se
define como:</li>
</ol>
<p><span class="math display">\[(\hat{\theta}-t^{(1-\alpha)}_{n-1}\cdot \hat{se}_B, \hat{\theta}+t^{(1-\alpha)}_{n-1}\cdot \hat{se}_B)\]</span>.</p>
<p>donde <span class="math inline">\(t^{(\alpha)}_{n-1}\)</span> denota denota el percentil <span class="math inline">\(100\cdot \alpha\)</span> de una
distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(n-1\)</span> grados de libertad.</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">n_nerve &lt;-<span class="st"> </span><span class="kw">nrow</span>(nerve_long)
li_t &lt;-<span class="st"> </span><span class="kw">round</span>(theta_hat <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, n_nerve <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(kurtosis), <span class="dv">2</span>)
ls_t &lt;-<span class="st"> </span><span class="kw">round</span>(theta_hat <span class="op">-</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, n_nerve <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(kurtosis), <span class="dv">2</span>)
<span class="kw">c</span>(li_t, ls_t)
<span class="co">#&gt; [1] 1.44 2.08</span></code></pre>
<p>Los intervalos normales y <span class="math inline">\(t\)</span> se valen de la estimación bootstrap del error estándar; sin embargo, el bootstrap se puede usar para estimar la función de
distribución de <span class="math inline">\(\hat{\theta}\)</span> por lo que no es necesario hacer supuestos
distribucionales para <span class="math inline">\(\hat{\theta}\)</span> sino que podemos estimarla como parte del
proceso de construir intervalos de confianza.</p>
<p>Veamos un histograma de las replicaciones bootstrap de <span class="math inline">\(\hat{\theta}^*\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">nerve_kurtosis &lt;-<span class="st"> </span><span class="kw">data_frame</span>(kurtosis)
hist_nerve &lt;-<span class="st"> </span><span class="kw">ggplot</span>(nerve_kurtosis, <span class="kw">aes</span>(<span class="dt">x =</span> kurtosis)) <span class="op">+</span><span class="st"> </span>
<span class="st">        </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">fill =</span> <span class="st">&quot;gray30&quot;</span>) <span class="op">+</span>
<span class="st">            </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">c</span>(li_normal, ls_normal, theta_hat), 
            <span class="dt">color =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">alpha =</span> <span class="fl">0.5</span>)

qq_nerve &lt;-<span class="st"> </span><span class="kw">ggplot</span>(nerve_kurtosis) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> kurtosis), <span class="dt">dparams =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(kurtosis), <span class="dt">sd =</span> <span class="kw">sd</span>(kurtosis))) 

<span class="kw">grid.arrange</span>(hist_nerve, qq_nerve, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">newpage =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-22-1.png" width="816" /></p>
<p>En el ejemplo anterior el supuesto de normalidad parece razonable, veamos
como se comparan los cuantiles de la estimación de la distribución de
<span class="math inline">\(\hat{\theta}\)</span> con los cuantiles de una normal:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">comma</span>(q_kurt &lt;-<span class="st"> </span><span class="kw">quantile</span>(kurtosis, <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.975</span>)))
<span class="kw">comma</span>(<span class="kw">qnorm</span>(<span class="dt">p =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.975</span>), <span class="dt">mean =</span> theta_hat, 
  <span class="dt">sd =</span> <span class="kw">sd</span>(kurtosis)))
<span class="co">#&gt;  2.5%    5%   10%   90%   95% 97.5% </span>
<span class="co">#&gt; &quot;1.4&quot; &quot;1.5&quot; &quot;1.5&quot; &quot;2.0&quot; &quot;2.0&quot; &quot;2.1&quot; </span>
<span class="co">#&gt; [1] &quot;1.4&quot; &quot;1.5&quot; &quot;1.5&quot; &quot;2.0&quot; &quot;2.0&quot; &quot;2.1&quot;</span></code></pre>
<p>Esto sugiere usar los cuantiles del histograma bootstrap para definir los
límites de los intervalos de confianza:</p>
<div class="caja">
<ol start="3" style="list-style-type: decimal">
<li><strong>Percentiles</strong>. Denotemos por <span class="math inline">\(G\)</span> la función de distribución acumulada de
<span class="math inline">\(\hat{\theta}^*\)</span> el intervalo percentil de <span class="math inline">\(1-2\alpha\)</span> se define por los
percentiles <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(1-\alpha\)</span> de <span class="math inline">\(G\)</span>
<span class="math display">\[(\theta^*_{\%,inf}, \theta^*_{\%,sup}) = (G^{-1}(\alpha), G^{-1}(1-\alpha))\]</span>
Por definición <span class="math inline">\(G^{-1}(\alpha)=\hat{\theta}^*(\alpha)\)</span>, esto es, el percentil
<span class="math inline">\(100\cdot \alpha\)</span> de la distribución bootstrap, por lo que podemos escribir el
intervalo bootstrap como
<span class="math display">\[(\theta^*_{\%,inf}, \theta^*_{\%,sup})=(\hat{\theta}^*(\alpha),\hat{\theta}^*(1-\alpha))\]</span></li>
</ol>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">arrange</span>(nerve_kurtosis, kurtosis)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">stat_ecdf</span>(<span class="kw">aes</span>(<span class="dt">x =</span> kurtosis)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_segment</span>(<span class="dt">data =</span> <span class="kw">data_frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="op">-</span><span class="ot">Inf</span>, <span class="op">-</span><span class="ot">Inf</span>, q_kurt[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>)]), 
        <span class="dt">xend =</span> q_kurt[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">6</span>)], <span class="dt">y =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>, <span class="dv">0</span>, <span class="dv">0</span>), 
        <span class="dt">yend =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>, <span class="fl">0.025</span>, <span class="fl">0.975</span>)), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">xend =</span> xend, <span class="dt">y =</span> y, 
        <span class="dt">yend =</span> yend), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="fl">0.4</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cuantiles muestrales&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;ecdf&quot;</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-24-1.png" width="384" /></p>
<p>Las expresiones de arriba hacen referencia a la situación bootstrap <em>ideal</em>
donde el número de replicaciones bootstrap es infinito, en la práctica usamos
aproximaciones. Y se procede como sigue:</p>
<div style="caja">
<p>Intervalo percentil:</p>
<ul>
<li><p>Generamos B muestras bootstrap independientes <span class="math inline">\(\textbf{x}^{*1},..., \textbf{x}^{*B}\)</span> y calculamos las replicaciones <span class="math inline">\(\hat{\theta}^{*b}=s(x^{*b}).\)</span></p></li>
<li>Sea <span class="math inline">\(\hat{\theta}^{*}_B(\alpha)\)</span> el percentil <span class="math inline">\(100\cdot\alpha\)</span> de la
distribución empírica de <span class="math inline">\(\hat{\theta}^{*}\)</span>, y <span class="math inline">\(\hat{\theta}^{*}_B(1-\alpha)\)</span>
el correspondiente al percentil <span class="math inline">\(100\cdot (1-\alpha)\)</span>, escribimos el intervalo
de percentil <span class="math inline">\(1-2\alpha\)</span> como
<span class="math display">\[(\theta^*_{\%,inf}, \theta^*_{\%,sup})\approx(\hat{\theta}^*_B(\alpha),\hat{\theta}^*_B(1-\alpha))\]</span></li>
</ul>
</div>
<pre class="sourceCode r"><code class="sourceCode r">ls_per &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">quantile</span>(kurtosis, <span class="dt">prob =</span> <span class="fl">0.975</span>), <span class="dv">2</span>)
li_per &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">quantile</span>(kurtosis, <span class="dt">prob =</span> <span class="fl">0.025</span>), <span class="dv">2</span>)
stringr<span class="op">::</span><span class="kw">str_c</span>(li_normal, ls_normal, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)
stringr<span class="op">::</span><span class="kw">str_c</span>(li_per, ls_per, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)
<span class="co">#&gt; [1] &quot;1.44,2.08&quot;</span>
<span class="co">#&gt; [1] &quot;1.43,2.06&quot;</span></code></pre>
<p>Si la distribución de <span class="math inline">\(\hat{\theta}^*\)</span> es aproximadamente normal, entonces
los intervalos normales y de percentiles serán similares.</p>
<p>Con el fin de comparar los intervalos creamos un ejemplo de simulación
(ejemplo tomado de <span class="citation">Efron and Tibshirani (<a href="#ref-efron">1993</a>)</span>), generamos una muestra de tamaño 10 de una
distribución normal estándar, supongamos que el parámetro de interés es
<span class="math inline">\(e^{\mu}\)</span> donde <span class="math inline">\(\mu\)</span> es la media poblacional.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">137612</span>)
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">10</span>)

boot_sim_exp &lt;-<span class="st"> </span><span class="cf">function</span>(){
  x_boot &lt;-<span class="st"> </span><span class="kw">sample</span>(x, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
  <span class="kw">exp</span>(<span class="kw">mean</span>(x_boot))
}
theta_boot &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">1000</span>, <span class="kw">boot_sim_exp</span>()) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">flatten_dbl</span>()
theta_boot_df &lt;-<span class="st"> </span><span class="kw">data_frame</span>(theta_boot)

hist_emu &lt;-<span class="st"> </span><span class="kw">ggplot</span>(theta_boot_df, <span class="kw">aes</span>(<span class="dt">x =</span> theta_boot)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;gray30&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.08</span>) 
qq_emu &lt;-<span class="st"> </span><span class="kw">ggplot</span>(theta_boot_df) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> theta_boot), 
        <span class="dt">dparams =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(theta_boot), <span class="dt">sd =</span> <span class="kw">sd</span>(theta_boot))) 

<span class="kw">grid.arrange</span>(hist_emu, qq_emu, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">newpage =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-26-1.png" width="816" /></p>
<p>La distribución empírica de <span class="math inline">\(\hat{\theta}^*\)</span> es asimétrica, por lo que no
esperamos que coincidan los intervalos.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Normal</span>
<span class="kw">round</span>(<span class="kw">exp</span>(<span class="kw">mean</span>(x)) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(theta_boot), <span class="dv">2</span>)
<span class="co">#&gt; [1] 0.33</span>
<span class="kw">round</span>(<span class="kw">exp</span>(<span class="kw">mean</span>(x)) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(theta_boot), <span class="dv">2</span>)
<span class="co">#&gt; [1] 1.62</span>

<span class="co">#Percentil</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(theta_boot, <span class="dt">prob =</span> <span class="fl">0.025</span>), <span class="dv">2</span>)
<span class="co">#&gt; 2.5% </span>
<span class="co">#&gt; 0.54</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(theta_boot, <span class="dt">prob =</span> <span class="fl">0.975</span>), <span class="dv">2</span>)
<span class="co">#&gt; 97.5% </span>
<span class="co">#&gt;  1.78</span></code></pre>
<p>La inspección del histograma deja claro que la aproximación normal no es
conveniente en este caso, veamos que ocurre cuando aplicamos la transformación
logarítmica.</p>
<pre class="sourceCode r"><code class="sourceCode r">hist_log &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data_frame</span>(theta_boot), <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log</span>(theta_boot))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;gray30&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.08</span>) 
qq_log &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data_frame</span>(theta_boot)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> <span class="kw">log</span>(theta_boot)), 
        <span class="dt">dparams =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(<span class="kw">log</span>(theta_boot)), <span class="dt">sd =</span> <span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)))) 

<span class="kw">grid.arrange</span>(hist_log, qq_log, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">newpage =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-28-1.png" width="816" /></p>
<p>Y los intervalos se comparan:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Normal</span>
<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>)
<span class="co">#&gt; [1] -0.64</span>
<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>)
<span class="co">#&gt; [1] 0.59</span>

<span class="co">#Percentil</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(<span class="kw">log</span>(theta_boot), <span class="dt">prob =</span> <span class="fl">0.025</span>), <span class="dv">2</span>)
<span class="co">#&gt;  2.5% </span>
<span class="co">#&gt; -0.62</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(<span class="kw">log</span>(theta_boot), <span class="dt">prob =</span> <span class="fl">0.975</span>), <span class="dv">2</span>)
<span class="co">#&gt; 97.5% </span>
<span class="co">#&gt;  0.58</span></code></pre>
<p>La transformación logarítmica convierte la distribución de <span class="math inline">\(\hat{\theta}\)</span> en
normal y por tanto los intervalos de <span class="math inline">\(\hat{\phi}^*=log(\hat{\theta}^*)\)</span> son
similares. La forma normal no es sorprendente pues <span class="math inline">\(\hat{\phi}^*=\bar{x}^*\)</span>.</p>
<p>Si mapeamos los intervalos normales calculados para <span class="math inline">\(log(\hat{\theta}^*)\)</span> de
regreso a la escala de <span class="math inline">\(\theta\)</span> obtenemos intervalos similares a los calculados
para <span class="math inline">\(\hat{\theta}^*\)</span> usando percentiles:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>))
<span class="co">#&gt; [1] 0.52729</span>
<span class="kw">exp</span>(<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>))
<span class="co">#&gt; [1] 1.804</span></code></pre>
<p>Podemos ver que el método de aplicar una transformación, calcular intervalos
usando la normal y aplicar la transformación inversa para volver a la escala
original genera intervalos de confianza atractivos, el problema con este
método es que requiere que conozcamos la transformación adecuada para cada
parámetro.</p>
<p>Por otra parte, podemos pensar en el método del percentil como un
algoritmo que incorpora la transformación de manera automática:</p>
<div class="caja&gt; **Lema**. Supongamos que la transformación $\hat{\phi}=m(\hat{\theta})$ normaliza la distribución de $\hat{\theta}$ de manera perfecta, $$\hat{\phi} \approx N(\phi, c^2)$$ para alguna desviación estándar $c$. Entonces el intervalo de percentil basado en $\hat{\theta}$ es igual a $$(m^{-1} (\hat{\phi}-z^{(1-\alpha)}c), m^{-1}(\hat{\phi}-z^{(\alpha)}c))$$ &lt;/div&gt; Se dice que el intervalo de confianza de percentiles es **invariante a transformaciones**. Existen otras alternativas al método del percentil y cubren otras fallas del intervalo normal. Por ejemplo, hay ocasiones en que $\hat{\theta}$ tiene una distribución normal sesgada: $$\hat{\theta} \approx N(\theta + sesgo, \hat{se}^2)$$ en este caso no existe una transformación $m(\theta)$ que _arregle_ el intervalo. &lt;div class=" caja="">
<ol start="3" style="list-style-type: decimal">
<li><strong>Intervalos acelerados y corregidos por sesgo</strong>. Esta es una versión
mejorada del intervalo de percentil, la denotamos <span class="math inline">\(BC_{a}\)</span> (<em>bias-corrected and
accelerated</em>).</li>
</ol>
<p>Usaremos un ejemplo de <span class="citation">Efron and Tibshirani (<a href="#ref-efron">1993</a>)</span>, los datos constan de los resultados
en dos pruebas espaciales de 26 niños con algún problema neurológico. Supongamos
que queremos calcular un intervalo de confianza de 90% para <span class="math inline">\(\theta=var(A)\)</span>.
El estimador plugin es:
<span class="math display">\[\hat{\theta}=\sum_{i=1}^n(A_i-\bar{A})^2/n\]</span>
notemos que el estimador <em>plug-in</em> es ligeramente menor que el estimador
usual insesgado:
<span class="math display">\[\hat{\theta}=\sum_{i=1}^n(A_i-\bar{A})^2/(n-1)\]</span></p>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bootstrap)

<span class="kw">ggplot</span>(spatial) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(A, B))</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/spatial-1.png" width="336" /></p>
<pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">sum</span>((spatial<span class="op">$</span>A <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(spatial<span class="op">$</span>A)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(spatial)
<span class="co">#&gt; [1] 171.53</span>
<span class="kw">sum</span>((spatial<span class="op">$</span>A <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(spatial<span class="op">$</span>A)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">nrow</span>(spatial) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
<span class="co">#&gt; [1] 178.4</span></code></pre>
<p>El método <span class="math inline">\(BC_{a}\)</span> corrige el sesgo de manera automática, lo cuál es una
de sus prinicipales ventajas comparado con el método del percentil.</p>
&lt;div class=“caja&gt;
Los extremos en los intervalos <span class="math inline">\(BC_{a}\)</span> están dados por percentiles de la
distribución bootstrap, los percentiles usados dependen de dos números <span class="math inline">\(\hat{a}\)</span>
y <span class="math inline">\(\hat{z}_0\)</span>, que se denominan la aceleración y la corrección del sesgo:
<span class="math display">\[BC_a : (\hat{\theta}_{inf}, \hat{\theta}_{sup})=(\hat{\theta}^*(\alpha_1), \hat{\theta}^*(\alpha_2))\]</span>
donde
<span class="math display">\[\alpha_1= \Phi\bigg(\hat{z}_0 + \frac{\hat{z}_0 + z^{(\alpha)}}{1- \hat{a}(\hat{z}_0 + z^{(\alpha)})}\bigg)\]</span>
<span class="math display">\[\alpha_2= \Phi\bigg(\hat{z}_0 + \frac{\hat{z}_0 + z^{(1-\alpha)}}{1- \hat{a}(\hat{z}_0 + z^{(1-\alpha)})}\bigg)\]</span>
y <span class="math inline">\(\Phi\)</span> es la función de distribución acumulada de la distribución normal estándar
y <span class="math inline">\(z^{\alpha}\)</span> es el percentil <span class="math inline">\(100 \cdot \alpha\)</span> de una distribución normal
estándar.
</div>
<p>Notemos que si <span class="math inline">\(\hat{a}\)</span> y <span class="math inline">\(\hat{z}_0\)</span> son cero entonces <span class="math inline">\(\alpha_1=\alpha\)</span><br />
y <span class="math inline">\(\alpha_2=1-\alpha\)</span>, obteniendo así los intervalos de percentiles.
El valor de la corrección por sesgo <span class="math inline">\(\hat{z}_0\)</span> se obtiene de la
propoción de de replicaciones bootstrap menores a la estimación original
<span class="math inline">\(\hat{\theta}\)</span>,</p>
<p><span class="math display">\[z_0=\Phi^{-1}\bigg(\frac{\#\{\hat{\theta}^*(b) &lt; \hat{\theta} \} }{B} \bigg)\]</span></p>
<p>a grandes razgos <span class="math inline">\(\hat{z}_0\)</span> mide la mediana del sesgo de <span class="math inline">\(\hat{\theta}^*\)</span>, esto
es, la discrepancia entre la mediana de <span class="math inline">\(\hat{\theta}^*\)</span> y <span class="math inline">\(\hat{\theta}\)</span> en
unidades normales.</p>
<p>Por su parte la aceleración <span class="math inline">\(\hat{a}\)</span> se refiere a la tasa de cambio del error
estándar de <span class="math inline">\(\hat{\theta}\)</span> respecto al verdadero valor del parámetro <span class="math inline">\(\theta\)</span>.
La aproximación estándar usual <span class="math inline">\(\hat{\theta} \approx N(\theta, se^2)\)</span> supone que
el error estándar de <span class="math inline">\(\hat{\theta}\)</span> es el mismo para toda <span class="math inline">\(\hat{\theta}\)</span>, esto
puede ser poco realista, en nuestro ejemplo, donde <span class="math inline">\(\hat{\theta}\)</span> es la varianza
si los datos provienen de una normal <span class="math inline">\(se(\hat{\theta})\)</span> depende de <span class="math inline">\(\theta\)</span>.
Una manera de calcular <span class="math inline">\(\hat{a}\)</span> es</p>
<p><span class="math display">\[\hat{a}=\frac{\sum_{i=1}^n (\hat{\theta}(\cdot) - \hat{\theta}(i))^3}{6\{\sum_{i=1}^n (\hat{\theta}(\cdot) - \hat{\theta}(i))^2\}^{3/2}}\]</span></p>
<p>Los intervalos <span class="math inline">\(BC_{a}\)</span> tienen 2 ventajas teóricas:</p>
<ol style="list-style-type: decimal">
<li><p>Respetan transformaciones, esto nos dice que los extremos del intervalo se
transforman de manera adecuada si cambiamos el parámetro de interés por una
función del mismo.</p></li>
<li><p>Su exactitud, los intervalos <span class="math inline">\(BC_{a}\)</span> tienen precisión de segundo orden, esto
es, los errores de cobertura se van a cero a una tasa de 1/n.</p></li>
</ol>
<p>Los intervalos <span class="math inline">\(BC_{a}\)</span> están implementados en el paquete boot (<code>boot.ci()</code>) y
en el paquete bootstrap (<code>bcanon()</code>). La desventaja de los intervalos <span class="math inline">\(BC_{a}\)</span> es
que requieren intenso cómputo estadístico, de acuerdo a <span class="citation">Efron and Tibshirani (<a href="#ref-efron">1993</a>)</span> al
menos <span class="math inline">\(B= 1000\)</span> replicaciones son necesairas para reducir el error de muestreo.</p>
<p>Ante esto surgen los intervalos ABC (approximate bootstrap confidence
intervals), que es un método para aproximar <span class="math inline">\(BC_{a}\)</span> analíticamente (usando
expansiones de Taylor).</p>
<p>Usando la implementación del paquete bootstrap:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bootstrap)
var_sesgada &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x)
<span class="kw">bcanon</span>(<span class="dt">x =</span> spatial[, <span class="dv">1</span>], <span class="dt">nboot =</span> <span class="dv">2000</span>, <span class="dt">theta =</span> var_sesgada, <span class="dt">alpha =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))
<span class="co">#&gt; $confpoints</span>
<span class="co">#&gt;      alpha bca point</span>
<span class="co">#&gt; [1,] 0.025    104.08</span>
<span class="co">#&gt; [2,] 0.975    281.70</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $z0</span>
<span class="co">#&gt; [1] 0.14717</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $acc</span>
<span class="co">#&gt; [1] 0.06124</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $u</span>
<span class="co">#&gt;  [1] 164.39 176.72 174.52 178.38 172.05 172.05 174.52 172.05 175.96 173.04</span>
<span class="co">#&gt; [11] 168.60 168.20 155.12 141.81 177.93 178.28 177.61 151.02 178.17 177.07</span>
<span class="co">#&gt; [21] 165.88 173.04 177.07 177.84 178.39 173.04</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $call</span>
<span class="co">#&gt; bcanon(x = spatial[, 1], nboot = 2000, theta = var_sesgada, alpha = c(0.025, </span>
<span class="co">#&gt;     0.975))</span></code></pre>
<p><img src="imagenes/manicule2.jpg" /> Comapara el intervalo anterior con los intervalos
normal y de percentiles.</p>
<p>Otros intervalos basados en bootstrap incluyen los intervalos pivotales y los
intervalos bootstrap-t. Sin embargo, BC y ABC son mejores alternativas.</p>
<div class="caja">
<ol start="4" style="list-style-type: decimal">
<li><strong>Intervalos pivotales</strong>. Sea <span class="math inline">\(\theta=s(P)\)</span> y <span class="math inline">\(\hat{\theta}=s(P_n)\)</span> definimos
el pivote <span class="math inline">\(R=\hat{\theta}-\theta\)</span>. Sea <span class="math inline">\(H(r)\)</span> la función de distribución
acumulada del pivote:
<span class="math display">\[H(r) = P(R&lt;r)\]</span></li>
</ol>
<p>Definimos <span class="math inline">\(C_n^*=(a,b)\)</span> donde:
<span class="math display">\[a=\hat{\theta}-H^{-1}(1-\alpha), b=\hat{\theta}-H^{-1}(\alpha)\]</span>
<span class="math inline">\(C_n^*\)</span> es un intervalo de confianza de <span class="math inline">\(1-2\alpha\)</span> para <span class="math inline">\(\theta\)</span>; sin
embargo, <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> dependen de la distribución desconocida <span class="math inline">\(H\)</span>, la podemos
estimar usando bootstrap:
<span class="math display">\[\hat{H}(r)=\frac{1}{B}\sum_{b=1}^B I(R^*_b \le r)\]</span>
y obtenemos
<span class="math display">\[C_n=(2\hat{\theta} - \hat{\theta}^*_{1-\alpha}, 2\hat{\theta} + \hat{\theta}^*_{1-\alpha})\]</span></p>
</div>
<div class="caja">
<p><strong>Exactitud en intervalos de confianza.</strong> Un intervalo de <span class="math inline">\(95%\)</span> de confianza
exacto no captura el verdadero valor <span class="math inline">\(2.5%\)</span> de las veces, en cada lado.</p>
<p>Un intervalo que sub-cubre un lado y sobre-cubre el otro es <strong>sesgado</strong>.</p>
</div>
<ul>
<li><p>Los intervalos estándar y de percentiles tienen exactitud de primer
orden: los errores de cobertura se van a cero a una tasa de <span class="math inline">\(1/\sqrt{n}\)</span>.</p></li>
<li><p>Los intervalos <span class="math inline">\(BC_a\)</span> tienen exactitud de segundo
orden: los errores de cobertura se van a cero a una tasa de <span class="math inline">\(1/n\)</span>.</p></li>
</ul>
</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references">
<div id="ref-efron">
<p>Efron, Bradley, and Robert J. Tibshirani. 1993. <em>An Introduction to the Bootstrap</em>. Monographs on Statistics and Applied Probability 57. Boca Raton, Florida, USA: Chapman &amp; Hall/CRC.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="el-estimador-bootstrap-del-error-estandar.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bootstrap-en-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tereom/est-computacional-2018/edit/master/05-bootstrap_no_parametrico.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["est-computacional-2018.pdf", "est-computacional-2018.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
