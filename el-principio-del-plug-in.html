<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Computacional</title>
  <meta name="description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Computacional" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  <meta name="github-repo" content="tereom/est-computacional-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Computacional" />
  
  <meta name="twitter:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  

<meta name="author" content="María Teresa Ortiz">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="bootstrap-no-parametrico.html">
<link rel="next" href="el-estimador-bootstrap-del-error-estandar.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/d3-3.5.6/d3.min.js"></script>
<link href="libs/profvis-0.3.5/profvis.css" rel="stylesheet" />
<script src="libs/profvis-0.3.5/profvis.js"></script>
<link href="libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="libs/highlight-6.2.0/highlight.js"></script>
<script src="libs/profvis-binding-0.3.5/profvis.js"></script>
<script src="libs/plotly-binding-4.8.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.39.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.39.2/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
<link rel="stylesheet" href="css/font-awesome.min.css" type="text/css" />
<link rel="stylesheet" href="css/cajas.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Computacional</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html"><i class="fa fa-check"></i>Temario</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#calificacion"><i class="fa fa-check"></i>Calificación</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#otros-recursos"><i class="fa fa-check"></i>Otros recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html"><i class="fa fa-check"></i><b>1</b> Introducción a visualización</a><ul>
<li class="chapter" data-level="" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html#el-cuarteto-de-ascombe"><i class="fa fa-check"></i>El cuarteto de Ascombe</a></li>
<li class="chapter" data-level="1.1" data-path="introduccion.html"><a href="introduccion.html"><i class="fa fa-check"></i><b>1.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-de-datos-en-la-estadistica"><i class="fa fa-check"></i>Visualización de datos en la estadística</a></li>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>1.2</b> Teoría de visualización de datos</a><ul>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#principios-generales-del-diseno-analitico"><i class="fa fa-check"></i>Principios generales del diseño analítico</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tecnicas-de-visualizacion"><i class="fa fa-check"></i>Técnicas de visualización</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#indicadores-de-calidad-grafica"><i class="fa fa-check"></i>Indicadores de calidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#factor-de-engano-chartjunk-y-pies"><i class="fa fa-check"></i>Factor de engaño, chartjunk y pies</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#series-de-tiempo-y-promedio-de-45"><i class="fa fa-check"></i>Series de tiempo y promedio de 45</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#pequenos-multiplos-y-densidad-grafica"><i class="fa fa-check"></i>Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tinta-de-datos"><i class="fa fa-check"></i>Tinta de datos</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#percepcion-de-escala"><i class="fa fa-check"></i>Percepción de escala</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#minard"><i class="fa fa-check"></i>Minard</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduccion-a-r-y-al-paquete-ggplot2.html"><a href="introduccion-a-r-y-al-paquete-ggplot2.html"><i class="fa fa-check"></i><b>2</b> Introducción a R y al paquete ggplot2</a><ul>
<li class="chapter" data-level="2.1" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html"><i class="fa fa-check"></i><b>2.1</b> R: primeros pasos</a><ul>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#r-en-analisis-de-datos"><i class="fa fa-check"></i>R en análisis de datos</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#paquetes-y-el-tidyverse"><i class="fa fa-check"></i>Paquetes y el Tidyverse</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#recursos"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html"><i class="fa fa-check"></i><b>2.2</b> Visualización con ggplot2</a><ul>
<li class="chapter" data-level="" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html#recursos-1"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-agrupacion-de-datos.html"><a href="manipulacion-y-agrupacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y agrupación de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html"><i class="fa fa-check"></i><b>3.1</b> Transformación de datos</a><ul>
<li><a href="transformacion-de-datos.html#separa-aplica-combina-split-apply-combine">Separa-aplica-combina (<em>split-apply-combine</em>)</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ejemplos-y-lectura-de-datos"><i class="fa fa-check"></i>Ejemplos y lectura de datos</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#filtrar"><i class="fa fa-check"></i>Filtrar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#seleccionar"><i class="fa fa-check"></i>Seleccionar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ordenar"><i class="fa fa-check"></i>Ordenar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#mutar"><i class="fa fa-check"></i>Mutar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#summarise-y-resumenes-por-grupo"><i class="fa fa-check"></i>Summarise y resúmenes por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#operador-pipeline"><i class="fa fa-check"></i>Operador pipeline</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#variables-por-grupo"><i class="fa fa-check"></i>Variables por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#verbos-de-dos-tablas"><i class="fa fa-check"></i>Verbos de dos tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="datos-limpios.html"><a href="datos-limpios.html"><i class="fa fa-check"></i><b>3.2</b> Datos limpios</a><ul>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#limpieza-bases-de-datos"><i class="fa fa-check"></i>Limpieza bases de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#los-encabezados-de-las-columanas-son-valores"><i class="fa fa-check"></i>Los encabezados de las columanas son valores</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-columna-asociada-a-mas-de-una-variable"><i class="fa fa-check"></i>Una columna asociada a más de una variable</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#variables-almacenadas-en-filas-y-columnas"><i class="fa fa-check"></i>Variables almacenadas en filas y columnas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#mas-de-un-tipo-de-observacion-en-una-misma-tabla"><i class="fa fa-check"></i>Mas de un tipo de observación en una misma tabla</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-misma-unidad-observacional-esta-almacenada-en-multiples-tablas"><i class="fa fa-check"></i>Una misma unidad observacional está almacenada en múltiples tablas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#otras-consideraciones"><i class="fa fa-check"></i>Otras consideraciones</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#recursos-adicionales"><i class="fa fa-check"></i>Recursos adicionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="temas-selectos-de-r.html"><a href="temas-selectos-de-r.html"><i class="fa fa-check"></i><b>4</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="4.1" data-path="funciones.html"><a href="funciones.html"><i class="fa fa-check"></i><b>4.1</b> Funciones</a><ul>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#estructura-de-una-funcion"><i class="fa fa-check"></i>Estructura de una función</a></li>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#observaciones-del-uso-de-funciones"><i class="fa fa-check"></i>Observaciones del uso de funciones</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="vectores.html"><a href="vectores.html"><i class="fa fa-check"></i><b>4.2</b> Vectores</a><ul>
<li class="chapter" data-level="" data-path="vectores.html"><a href="vectores.html#propiedades"><i class="fa fa-check"></i>Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="iteracion.html"><a href="iteracion.html"><i class="fa fa-check"></i><b>4.3</b> Iteración</a></li>
<li class="chapter" data-level="4.4" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html"><i class="fa fa-check"></i><b>4.4</b> Rendimiento en R</a><ul>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#diagnosticar"><i class="fa fa-check"></i>Diagnosticar</a></li>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#estrategias-para-mejorar-desempeno"><i class="fa fa-check"></i>Estrategias para mejorar desempeño</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduccion-a-probabilidad.html"><a href="introduccion-a-probabilidad.html"><i class="fa fa-check"></i><b>5</b> Introducción a probabilidad</a><ul>
<li class="chapter" data-level="5.1" data-path="probabilidad-como-extension-a-proporcion.html"><a href="probabilidad-como-extension-a-proporcion.html"><i class="fa fa-check"></i><b>5.1</b> Probabilidad como extensión a proporción</a></li>
<li class="chapter" data-level="5.2" data-path="interpretacion-frecuentista-de-probabilidad.html"><a href="interpretacion-frecuentista-de-probabilidad.html"><i class="fa fa-check"></i><b>5.2</b> Interpretación frecuentista de probabilidad</a></li>
<li class="chapter" data-level="5.3" data-path="simulacion-para-el-calculo-de-probabilidades.html"><a href="simulacion-para-el-calculo-de-probabilidades.html"><i class="fa fa-check"></i><b>5.3</b> Simulación para el cálculo de probabilidades</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html"><i class="fa fa-check"></i><b>5.4</b> Probabilidad: definición matemática</a><ul>
<li class="chapter" data-level="5.4.1" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html#propiedades-de-la-funcion-de-probabilidad"><i class="fa fa-check"></i><b>5.4.1</b> Propiedades de la función de probabilidad:</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>5.5</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bootstrap-no-parametrico.html"><a href="bootstrap-no-parametrico.html"><i class="fa fa-check"></i><b>6</b> Bootstrap no paramétrico</a><ul>
<li class="chapter" data-level="6.1" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html"><i class="fa fa-check"></i><b>6.1</b> El principio del plug-in</a><ul>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#muestras-aleatorias"><i class="fa fa-check"></i>Muestras aleatorias</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#funcion-de-distribucion-empirica"><i class="fa fa-check"></i>Función de distribución empírica</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#parametros-y-estadisticas"><i class="fa fa-check"></i>Parámetros y estadísticas</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#distribuciones-muestrales-y-errores-estandar"><i class="fa fa-check"></i>Distribuciones muestrales y errores estándar</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html"><i class="fa fa-check"></i><b>6.2</b> El estimador bootstrap del error estándar</a><ul>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#variacion-en-distribuciones-bootstrap"><i class="fa fa-check"></i>Variación en distribuciones bootstrap</a></li>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#mas-alla-de-muestras-aleatorias-simples"><i class="fa fa-check"></i>Más alla de muestras aleatorias simples</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>6.3</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="6.4" data-path="bootstrap-en-r.html"><a href="bootstrap-en-r.html"><i class="fa fa-check"></i><b>6.4</b> Bootstrap en R</a></li>
<li class="chapter" data-level="6.5" data-path="conclusiones-y-observaciones.html"><a href="conclusiones-y-observaciones.html"><i class="fa fa-check"></i><b>6.5</b> Conclusiones y observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="teoria-basica-de-simulacion.html"><a href="teoria-basica-de-simulacion.html"><i class="fa fa-check"></i><b>7</b> Teoría básica de simulación</a><ul>
<li class="chapter" data-level="7.1" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html"><i class="fa fa-check"></i><b>7.1</b> Números pseudoaleatorios</a><ul>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#generadores-congruenciales-y-mersenne-twister"><i class="fa fa-check"></i>Generadores congruenciales y Mersenne-Twister</a></li>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#pruebas-de-aleatoriedad"><i class="fa fa-check"></i>Pruebas de aleatoriedad</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html"><i class="fa fa-check"></i><b>7.2</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-discretas-importantes"><i class="fa fa-check"></i>Familias discretas importantes</a></li>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-continuas-importantes"><i class="fa fa-check"></i>Familias Continuas importantes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html"><i class="fa fa-check"></i><b>7.3</b> Simulación de variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aletaorias-discretas"><i class="fa fa-check"></i>Variables aletaorias discretas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i>Variables aleatorias continuas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo-1"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html"><i class="fa fa-check"></i><b>8</b> Simulación de modelos</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html#para-que-simular-de-un-modelo"><i class="fa fa-check"></i>¿Para qué simular de un modelo?</a></li>
<li class="chapter" data-level="8.1" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html"><i class="fa fa-check"></i><b>8.1</b> Distribuciones multivariadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#regla-de-bayes"><i class="fa fa-check"></i>Regla de Bayes</a></li>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#independencia"><i class="fa fa-check"></i>Independencia</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-graficos-y-simulacion-predictiva.html"><a href="modelos-graficos-y-simulacion-predictiva.html"><i class="fa fa-check"></i><b>8.2</b> Modelos gráficos y simulación predictiva</a></li>
<li class="chapter" data-level="8.3" data-path="inferencia-visual.html"><a href="inferencia-visual.html"><i class="fa fa-check"></i><b>8.3</b> Inferencia visual</a><ul>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia"><i class="fa fa-check"></i>Inferencia</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#protocolos-de-inferencia-visual"><i class="fa fa-check"></i>Protocolos de inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#pruebas-de-hipotesis-tipicas"><i class="fa fa-check"></i>Pruebas de hipótesis típicas</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia-visual-1"><i class="fa fa-check"></i>Inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#mas-alla-que-permutacion"><i class="fa fa-check"></i>Más allá que permutación</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#otras-consideraciones-1"><i class="fa fa-check"></i>Otras consideraciones</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><a href="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><i class="fa fa-check"></i><b>8.4</b> Simulación para cálculo de tamaño de muestra/poder estadístico</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inferencia-parametrica.html"><a href="inferencia-parametrica.html"><i class="fa fa-check"></i><b>9</b> Inferencia paramétrica</a><ul>
<li class="chapter" data-level="9.1" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html"><i class="fa fa-check"></i><b>9.1</b> Máxima verosimilitud</a><ul>
<li class="chapter" data-level="" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html#propiedades-de-los-estimadores-de-maxima-verosimilitud"><i class="fa fa-check"></i>Propiedades de los estimadores de máxima verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="bootstrap-parametrico.html"><a href="bootstrap-parametrico.html"><i class="fa fa-check"></i><b>9.2</b> Bootstrap paramétrico</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="analisis-bayesiano.html"><a href="analisis-bayesiano.html"><i class="fa fa-check"></i><b>10</b> Análisis bayesiano</a><ul>
<li class="chapter" data-level="10.1" data-path="probabilidad-subjetiva.html"><a href="probabilidad-subjetiva.html"><i class="fa fa-check"></i><b>10.1</b> Probabilidad subjetiva</a></li>
<li class="chapter" data-level="10.2" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html"><i class="fa fa-check"></i><b>10.2</b> Regla de Bayes e inferencia bayesiana</a><ul>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#regla-de-bayes-en-modelos-y-datos"><i class="fa fa-check"></i>Regla de Bayes en modelos y datos</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#objetivos-de-la-inferencia"><i class="fa fa-check"></i>Objetivos de la inferencia</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#calculo-de-la-distribucion-posterior"><i class="fa fa-check"></i>Cálculo de la distribución posterior</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html"><i class="fa fa-check"></i><b>10.3</b> Distribuciones conjugadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html#ejemplo-bernoulli"><i class="fa fa-check"></i>Ejemplo: Bernoulli</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="aproximacion-por-cuadricula.html"><a href="aproximacion-por-cuadricula.html"><i class="fa fa-check"></i><b>10.4</b> Aproximación por cuadrícula</a></li>
<li class="chapter" data-level="10.5" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>10.5</b> MCMC</a><ul>
<li class="chapter" data-level="" data-path="mcmc.html"><a href="mcmc.html#introduccion-metropolis"><i class="fa fa-check"></i>Introducción Metrópolis</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="metropolis.html"><a href="metropolis.html"><i class="fa fa-check"></i><b>10.6</b> Metrópolis</a><ul>
<li class="chapter" data-level="" data-path="metropolis.html"><a href="metropolis.html#inferencia-de-dos-proporciones-binomiales"><i class="fa fa-check"></i>Inferencia de dos proporciones binomiales</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html"><i class="fa fa-check"></i><b>10.7</b> Muestreador de Gibbs</a><ul>
<li class="chapter" data-level="" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html#conclusiones-y-observaciones-metropolis-y-gibbs"><i class="fa fa-check"></i>Conclusiones y observaciones Metrópolis y Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="jags.html"><a href="jags.html"><i class="fa fa-check"></i><b>10.8</b> JAGS</a><ul>
<li class="chapter" data-level="" data-path="jags.html"><a href="jags.html#ejemplo-normal-1"><i class="fa fa-check"></i>Ejemplo normal</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="diagnosticos.html"><a href="diagnosticos.html"><i class="fa fa-check"></i><b>10.9</b> Diagnósticos</a><ul>
<li class="chapter" data-level="" data-path="diagnosticos.html"><a href="diagnosticos.html#recomendaciones-generales"><i class="fa fa-check"></i>Recomendaciones generales</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html"><i class="fa fa-check"></i><b>10.10</b> HMC y Stan</a><ul>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#muestreo-hmc"><i class="fa fa-check"></i>Muestreo HMC</a></li>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#iniciales"><i class="fa fa-check"></i>Iniciales</a></li>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#recursos-adicionales-de-stan"><i class="fa fa-check"></i>Recursos adicionales de Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html"><i class="fa fa-check"></i><b>10.11</b> Modelos jerárquicos</a><ul>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#modelo-jerarquico-una-moneda"><i class="fa fa-check"></i>Modelo jerárquico una moneda</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#multiples-monedas-de-una-misma-fabrica"><i class="fa fa-check"></i>Multiples monedas de una misma fábrica</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#ejemplo-estimacion-de-tasas-de-mortalidad"><i class="fa fa-check"></i>Ejemplo: estimación de tasas de mortalidad</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#ejemplo-conteo-rapido"><i class="fa fa-check"></i>Ejemplo: conteo rápido</a></li>
</ul></li>
<li class="chapter" data-level="10.12" data-path="flujo-de-trabajo-para-el-analisis-bayesiano.html"><a href="flujo-de-trabajo-para-el-analisis-bayesiano.html"><i class="fa fa-check"></i><b>10.12</b> Flujo de trabajo para el análisis bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a><ul>
<li class="chapter" data-level="" data-path="transformacion-de-datos-1.html"><a href="transformacion-de-datos-1.html"><i class="fa fa-check"></i>2-Transformación de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios-1.html"><a href="datos-limpios-1.html"><i class="fa fa-check"></i>3-Datos Limpios</a></li>
<li class="chapter" data-level="" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i>4-Probabilidad</a></li>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i>5-Bootstrap</a><ul>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html#solucion"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html"><i class="fa fa-check"></i>6-Cobertura de intervalos de confianza</a><ul>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html#solucion-1"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-1.html"><a href="simulacion-de-modelos-1.html"><i class="fa fa-check"></i>7-Simulación de modelos</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-de-regresion.html"><a href="simulacion-de-modelos-de-regresion.html"><i class="fa fa-check"></i>8-Simulación de modelos de regresión</a></li>
<li class="chapter" data-level="" data-path="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><a href="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><i class="fa fa-check"></i>9-Inferencia gráfica, tamaño de muestra, bootstrap paramétrico.</a><ul>
<li class="chapter" data-level="" data-path="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><a href="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html#solucion-2"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="familias-conjugadas.html"><a href="familias-conjugadas.html"><i class="fa fa-check"></i>10-Familias conjugadas</a></li>
<li class="chapter" data-level="" data-path="metropolis-2.html"><a href="metropolis-2.html"><i class="fa fa-check"></i>11-Metropolis</a><ul>
<li class="chapter" data-level="" data-path="metropolis-2.html"><a href="metropolis-2.html#solucion-3"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="mcmc-convergencia.html"><a href="mcmc-convergencia.html"><i class="fa fa-check"></i>12-MCMC convergencia</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html"><i class="fa fa-check"></i>13-Modelos jerárquicos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="el-principio-del-plug-in" class="section level2">
<h2><span class="header-section-number">6.1</span> El principio del plug-in</h2>
<div id="muestras-aleatorias" class="section level3 unnumbered">
<h3>Muestras aleatorias</h3>
<p>Supongamos que tenemos una población finita o <em>universo</em> <span class="math inline">\(U\)</span>, conformado
por unidades individuales con propiedades que nos gustaría aprender (opinión
política, nivel educativo, preferencias de consumo, …). Debido a que es muy
difícil y caro examinar cada unidad en <span class="math inline">\(U\)</span> seleccionamos una muestra aleatoria.</p>
<div class="caja">
<p>Una <strong>muestra aleatoria</strong> de tamaño <span class="math inline">\(n\)</span> se define como una colección de <span class="math inline">\(n\)</span>
unidades <span class="math inline">\(u_1,...,u_n\)</span> seleccionadas aleatoriamente de una población <span class="math inline">\(U\)</span>.</p>
<p>Una vez que se selecciona una muestra aleatoria, los <strong>datos observados</strong> son la
colección de medidas <span class="math inline">\(x_1,...,x_n\)</span>, también denotadas
<span class="math inline">\(\textbf{x} = (x_1,...,x_n)\)</span>.</p>
</div>
<p>En principio, el proceso de muestreo es como sigue:</p>
<ol style="list-style-type: decimal">
<li><p>Seleccionamos <span class="math inline">\(n\)</span> enteros de manera independiente (con probabilidad <span class="math inline">\(1/N\)</span>),
cada uno de ellos asociado a un número entre <span class="math inline">\(1\)</span> y <span class="math inline">\(N\)</span>.</p></li>
<li><p>Los enteros determinan las unidades que seleccionamos y tomamos medidas
a cada unidad.</p></li>
</ol>
<p>En la práctica el proceso de selección suele ser más complicado y la
definición de la población <span class="math inline">\(U\)</span> suele ser deficiente; sin embargo, el marco
conceptual sigue siendo útil para entender la inferencia estadística.</p>
<div class="caja">
<p>Nuestra definición de muestra aleatoria comprende muestras con y sin reemplazo:</p>
<ul>
<li><p><strong>muestra sin reemplazo:</strong> una unidad particular puede aparecer a lo más una
vez.</p></li>
<li><strong>muestra con reemplazo:</strong> permite que una unidad aparezca más de una vez.</li>
</ul>
</div>
<ul>
<li><p>Es más común tomar muestras sin remplazo, sin embargo, <strong>para hacer inferencia
suele ser más sencillo permitir repeticiones (muestreo con
remplazo)</strong> y si el tamaño de la muestra <span class="math inline">\(n\)</span> es mucho más chico que la población
<span class="math inline">\(N\)</span>, la probabilidad de muestrear la misma unidad más de una vez es chica.</p></li>
<li><p>El caso particular en el que obtenemos las medidas de interés de cada unidad
en la población se denomina <strong>censo</strong>, y denotamos al conjunto de datos
observados de la población por <span class="math inline">\(\mathcal{X}\)</span>.</p></li>
</ul>
<p>En general, no nos interesa simplemente describir la muestra que observamos
sino que queremos aprender acerca de la población de donde se seleccionó la
muestra:</p>
<div class="caja">
<p>El objetivo de la <strong>inferencia estadística</strong> es expresar lo que hemos aprendido
de la población <span class="math inline">\(\mathcal{X}\)</span> a partir de los datos observados <span class="math inline">\(\textbf{x}\)</span>.</p>
</div>
<div id="ejemplo-enlace" class="section level4 unnumbered">
<h4>Ejemplo: ENLACE</h4>
<p>Veamos un ejemplo donde tomamos una muestra de 300 escuelas primarias
de la Ciudad de México, de un universo de 3,200 escuelas,</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># universo</span>
primaria &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/primarias.csv&quot;</span>)
<span class="co">#&gt; Parsed with column specification:</span>
<span class="co">#&gt; cols(</span>
<span class="co">#&gt;   clave = col_character(),</span>
<span class="co">#&gt;   turno = col_character(),</span>
<span class="co">#&gt;   tipo = col_character(),</span>
<span class="co">#&gt;   mun = col_double(),</span>
<span class="co">#&gt;   esp_3 = col_double(),</span>
<span class="co">#&gt;   esp_6 = col_double()</span>
<span class="co">#&gt; )</span>
<span class="kw">glimpse</span>(primaria)
<span class="co">#&gt; Observations: 3,202</span>
<span class="co">#&gt; Variables: 6</span>
<span class="co">#&gt; $ clave &lt;chr&gt; &quot;09DBN0006J&quot;, &quot;09DBN0007I&quot;, &quot;09DBN0008H&quot;, &quot;09DBN0015R&quot;, ...</span>
<span class="co">#&gt; $ turno &lt;chr&gt; &quot;NOCTURNO&quot;, &quot;NOCTURNO&quot;, &quot;NOCTURNO&quot;, &quot;NOCTURNO&quot;, &quot;NOCTURN...</span>
<span class="co">#&gt; $ tipo  &lt;chr&gt; &quot;GENERAL&quot;, &quot;GENERAL&quot;, &quot;GENERAL&quot;, &quot;GENERAL&quot;, &quot;GENERAL&quot;, &quot;...</span>
<span class="co">#&gt; $ mun   &lt;dbl&gt; 17, 28, 28, 14, 14, 17, 17, 14, 14, 14, 16, 16, 16, 16, ...</span>
<span class="co">#&gt; $ esp_3 &lt;dbl&gt; 483.14, 571.03, 418.50, 776.57, 714.09, 659.04, 703.04, ...</span>
<span class="co">#&gt; $ esp_6 &lt;dbl&gt; 513.98, 455.92, 561.27, 540.32, 670.00, 570.04, 606.64, ...</span>
<span class="kw">set.seed</span>(<span class="dv">16021</span>)
n &lt;-<span class="st"> </span><span class="dv">300</span>
<span class="co"># muestra</span>
primaria_muestra &lt;-<span class="st"> </span><span class="kw">sample_n</span>(primaria, n) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">clase =</span> <span class="st">&quot;muestra&quot;</span>)</code></pre>
<p>para cada escuela en la muestra tenemos la medida <span class="math inline">\(x_i\)</span>, conformada por el
promedio de las calificaciones en español de los alumnos de tercero y sexto
de primaria (prueba ENLACE 2010):
<span class="math display">\[x_i=(esp_{3i}, esp_{6i})\]</span></p>
<p>En este ejemplo contamos con un censo de las escuelas y tomamos la muestra
aleatoria de la tabla de datos general, sin embargo, es común contar únicamente
con la muestra.</p>
<p>Para español 3<sup>o</sup> de primaria la media observada es</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(primaria_muestra<span class="op">$</span>esp_<span class="dv">3</span>)
<span class="co">#&gt; [1] 577.27</span></code></pre>
<p>La media muestral es una estadística descriptiva de la muestra, pero también la
podemos usar para describir a la población de escuelas.</p>
<p>Al usar la media observada para describir a la población estamos aplicando el
principio del <em>plug-in</em> que dice que una característica dada de una distribución
puede ser aproximada por la equivalente evaluada en la distribución empírica de
una muestra aleatoria.</p>
</div>
</div>
<div id="funcion-de-distribucion-empirica" class="section level3 unnumbered">
<h3>Función de distribución empírica</h3>
<div class="caja">
<p>Dada una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> de una distribución de probabilidad
<span class="math inline">\(P\)</span>, la <strong>función de distribución empírica</strong> <span class="math inline">\(P_n\)</span> se define como la
distribución que asigna probabilidad <span class="math inline">\(1/n\)</span> a cada valor <span class="math inline">\(x_i\)</span> con <span class="math inline">\(i=1,2,...,n\)</span>.</p>
<p>En otras palabras, <span class="math inline">\(P_n\)</span> asigna a un conjunto <span class="math inline">\(A\)</span> en el espacio muestral de <span class="math inline">\(x\)</span>
la probabilidad empírica:</p>
<p><span class="math display">\[P_n(A)=\#\{x_i \in A \}/n\]</span></p>
</div>
<!--Ahora, muchos problemas de inferencia estadística involucran la estimación
de algún aspecto de una distribución de de probabilidad $P$ en base a una 
muestra aleatoria obtenida de $P$. -->
<ul>
<li><p>La función de distribución empírica <span class="math inline">\(P_n\)</span> es una estimación de la distribución
completa <span class="math inline">\(P\)</span>, por lo que una manera inmediata de estimar aspectos de <span class="math inline">\(P\)</span>
(e.g media o mediana) es calcular el aspecto correspondiente de <span class="math inline">\(P_n\)</span>.</p></li>
<li><p>En cuanto a la teoría el principio del <em>plug-in</em> está soportado por el teorema
de <a href="https://www.stat.berkeley.edu/~bartlett/courses/2013spring-stat210b/notes/8notes.pdf">Glivenko Cantelli</a>:</p>
<p>Sea <span class="math inline">\(X_1,...,X_n\)</span> una muestra aleatoria de una distribución <span class="math inline">\(P\)</span>, con
distribución empírica <span class="math inline">\(P_n\)</span> entonces
<span class="math display">\[\sup_{x \in \mathcal{R}}|P_n(x)-P(x)|\to_p0\]</span>
casi seguro.</p></li>
</ul>
<p>Regresando al ejemplo de las escuelas, comparemos la distribución poblacional y
la distribución empírica.</p>
<pre class="sourceCode r"><code class="sourceCode r">primaria_long &lt;-<span class="st"> </span>primaria <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">clase =</span> <span class="st">&quot;población&quot;) %&gt;% </span>
<span class="st">    rbind(primaria_muestra) %&gt;% </span>
<span class="st">    gather(grado, calif, esp_3:esp_6)</span>
<span class="st">    </span>
<span class="st">ggplot(primaria_long, aes(x = calif)) +</span>
<span class="st">  geom_histogram(aes(y = ..density..), binwidth = 20, fill = &quot;</span>darkgray<span class="st">&quot;) +</span>
<span class="st">  facet_grid(grado ~ clase)</span></code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/distribucion_empirica-1.png" width="480" /></p>
<p>Podemos comparar la función de distribución acumulada empírica y la función de
distribución acumulada poblacional:</p>
<p>En la siguiente gráfica la curva roja
representa la función de distribución acumulada empírica y la curva con relleno
gris la función de distribución acumulada poblacional.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">stat_ecdf</span>(<span class="dt">data =</span> <span class="kw">filter</span>(primaria_long, clase <span class="op">==</span><span class="st"> &quot;población&quot;), </span>
<span class="st">        aes(x = calif, ymin=0, ymax=..y..), geom = &quot;</span>ribbon<span class="st">&quot;, pad = TRUE, alpha = 0.5, </span>
<span class="st">        fill = &quot;</span>gray<span class="st">&quot;, color = &quot;</span>darkgray<span class="st">&quot;)  +</span>
<span class="st">    stat_ecdf(data = filter(primaria_long, clase == &quot;</span>muestra<span class="st">&quot;), </span>
<span class="st">        aes(x = calif), geom = &quot;</span>step<span class="st">&quot;, color = &quot;</span>red<span class="st">&quot;) +</span>
<span class="st">    facet_grid(~ grado) +</span>
<span class="st">    labs(color = &quot;&quot;)</span></code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-2-1.png" width="672" height="300px" /></p>
<p>Cuando la variable de interés toma pocos valores es fácil ver la distribución
empírica, supongamos que la medición de las unidades que nos interesa es la
variable tipo de escuela, entonces la distribución empírica en la muestra es</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(primaria_muestra<span class="op">$</span>tipo) <span class="op">/</span><span class="st"> </span>n
<span class="co">#&gt; </span>
<span class="co">#&gt;    GENERAL PARTICULAR </span>
<span class="co">#&gt;    0.67667    0.32333</span></code></pre>
<p>Vale la pena notar que pasar de la muestra desagregada a la distribución
empírica (lista de valores y la proporción que ocurre cada una en la muestra)
no conlleva ninguna pérdida de información:<br />
<em>el vector de frecuencias observadas es un <strong>estadístico suficiente</strong> para la
verdadera distribución.</em></p>
<p>Esto quiere decir que toda la información de <span class="math inline">\(P\)</span> contenida en el vector de
observaciones <span class="math inline">\(\textbf{x}\)</span> está también contenida en <span class="math inline">\(P_n\)</span>.</p>
<p><strong>Nota</strong>: el teorema de suficiencia asume que las observaciones <span class="math inline">\(\textbf{x}\)</span> son
una muestra aleatoria de la distribución <span class="math inline">\(P\)</span>, este no es siempre el caso
(e.g. si tenemos una serie de tiempo).</p>
</div>
<div id="parametros-y-estadisticas" class="section level3 unnumbered">
<h3>Parámetros y estadísticas</h3>
<p>Cuando aplicamos teoría estadística a problemas reales, es común que las
respuestas estén dadas en términos de distribuciones de probabilidad. Por
ejemplo, podemos preguntarnos que tan correlacionados están los resultados de
las pruebas de español correspondientes a 3<sup>o</sup> y 6<sup>o</sup>. Si conocemos la
distribución de probabilidad <span class="math inline">\(P\)</span> contestar esta pregunta es simplemente cuestión
de aritmética, el coeficiente de correlación poblacional esta dado por:</p>
<p><span class="math display">\[corr(y,z) = \frac{\sum_{j=1}^{N}(Y_j - \mu_y)(Z_j-\mu_z)}
{[\sum_{j=1}^{N}(Y_j - \mu_y)^2\sum_{j=1}^{N}(Z_j - \mu_z)^2]^{1/2}}\]</span></p>
<p>en nuestro ejemplo <span class="math inline">\((Y_j,Z_j)\)</span> son el j-ésimo punto en la población de escuelas
primarias <span class="math inline">\(\mathcal{X}\)</span>, <span class="math inline">\(\mu_y=\sum Y_j/3311\)</span> y <span class="math inline">\(\mu_z=\sum Z_j/3311\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(primaria, <span class="kw">aes</span>(<span class="dt">x =</span> esp_<span class="dv">3</span>, <span class="dt">y =</span> esp_<span class="dv">6</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/grafica_corr-1.png" width="300px" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(primaria<span class="op">$</span>esp_<span class="dv">3</span>, primaria<span class="op">$</span>esp_<span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)
<span class="co">#&gt; [1] 0.72</span></code></pre>
<p>Si no tenemos un censo debemos inferir, podríamos estimar la correlación
<span class="math inline">\(corr(y,z)\)</span> a través del coeficiente de correlación muestral:</p>
<p><span class="math display">\[\hat{corr}(y,z) = \frac{\sum_{j=1}^{n}(y_j - \hat{\mu}_y)(z_j-\hat{\mu}_z)}
{[\sum_{j=1}^{n}(y_j - \hat{\mu}_y)^2\sum_{j=1}^{n}(z_j - \hat{\mu}_z)^2]^{1/2}}\]</span></p>
<p>recordando que la distribución empírica es una estimación de la distribución
completa.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(primaria_muestra<span class="op">$</span>esp_<span class="dv">3</span>, primaria_muestra<span class="op">$</span>esp_<span class="dv">6</span>)
<span class="co">#&gt; [1] 0.6822</span></code></pre>
<p>Al igual que la media esto es una estimación <em>plug-in</em>. Otros ejemplos son:</p>
<ul>
<li>Supongamos que nos interesa estimar la mediana de las calificaciones
de español para 3^o de primaria:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">median</span>(primaria_muestra<span class="op">$</span>esp_<span class="dv">3</span>)
<span class="co">#&gt; [1] 562.46</span></code></pre>
<ul>
<li>Supongamos que nos interesa estimar la probabilidad de que la calificación de
español de una escuela sea mayor a 700:</li>
</ul>
<p><span class="math display">\[\theta=\frac{1}{N}\sum_{j=1}^N I_{\{Y_i&gt;700\}}\]</span></p>
<p>donde <span class="math inline">\(I_{\{\cdot\}}\)</span> es la función indicadora.</p>
<p>La estimación <em>plug-in</em> de <span class="math inline">\(\hat{\theta}\)</span> sería:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(primaria_muestra<span class="op">$</span>esp_<span class="dv">3</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">700</span>) <span class="op">/</span><span class="st"> </span>n
<span class="co">#&gt; [1] 0.056667</span></code></pre>
<div id="ejemplo-dado" class="section level4 unnumbered">
<h4>Ejemplo: dado</h4>
<p>Observamos 100 lanzamientos de un dado, obteniendo la siguiente distribución
empírica:</p>
<pre class="sourceCode r"><code class="sourceCode r">dado &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/dado.csv&quot;</span>, <span class="dt">header=</span><span class="ot">TRUE</span>, <span class="dt">quote=</span><span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st">&quot;</span>)
<span class="kw">prop.table</span>(<span class="kw">table</span>(dado<span class="op">$</span>x))
<span class="co">#&gt; </span>
<span class="co">#&gt;    1    2    3    4    5    6 </span>
<span class="co">#&gt; 0.13 0.19 0.10 0.17 0.14 0.27</span></code></pre>
<p>En este caso no tenemos un censo, solo contamos con la muestra. Una pregunta
de inferencia que surge de manera natural es si el dado es justo, esto es,
si la distribución que generó esta muestra tiene una distribución
<span class="math inline">\(P = (1/6, 1/6, 1/6,1/6, 1/6, 1/6)\)</span>.</p>
<p>Para resolver esta pregunta, debemos hacer inferencia de la distribución
empírica.</p>
<p>Antes de proseguir repasemos dos conceptos importantes: parámetros y
estadísticos:</p>
<div class="caja">
<p>Un <strong>parámetro</strong> es una función de la distribución de probabilidad
<span class="math inline">\(\theta=t(P)\)</span>, mientras que una <strong>estadística</strong> es una función de la
muestra <span class="math inline">\(\textbf{x}\)</span>.</p>
</div>
<p>Por ejemplo, la <span class="math inline">\(corr(x,y)\)</span> es un parámetro de <span class="math inline">\(P\)</span> y <span class="math inline">\(\hat{corr}(x,y)\)</span> es una
estadística con base en <span class="math inline">\(\textbf{x}\)</span> y <span class="math inline">\(\textbf{y}\)</span>.</p>
<p>Entonces:</p>
<div class="caja">
<p>El <strong>principio del <em>plug-in</em></strong> es un método para estimar parámetros a
partir de muestras; la estimación <em>plug-in</em> de un parámetro <span class="math inline">\(\theta=t(P)\)</span> se
define como:
<span class="math display">\[\hat{\theta}=t(P_n).\]</span></p>
</div>
<p>Es decir, estimamos la función <span class="math inline">\(\theta = t(P)\)</span> de la distribución de
probabilidad <span class="math inline">\(P\)</span> con la misma función aplicada en la distribución empírica
<span class="math inline">\(\hat{\theta}=t(P_n)\)</span>.</p>
<p>¿Qué tan <em>bien</em> funciona el principio del <em>plug-in</em>?</p>
<p>Suele ser muy bueno cuando la única información disponible de <span class="math inline">\(P\)</span> es la
muestra <span class="math inline">\(\textbf{x}\)</span>, bajo esta circunstancia <span class="math inline">\(\hat{\theta}=t(P_n)\)</span> no puede
ser superado como estimador de <span class="math inline">\(\theta=t(P)\)</span>, al menos no en el sentido
asintótico de teoría estadística <span class="math inline">\((n\to\infty)\)</span>.</p>
<p>El principio del <em>plug-in</em> provee de una estimación más no habla de precisión:
usaremos el bootstrap para estudiar el sesgo y el error estándar del
estimador <em>plug-in</em> <span class="math inline">\(\hat{\theta}=t(P_n)\)</span>.</p>
</div>
</div>
<div id="distribuciones-muestrales-y-errores-estandar" class="section level3 unnumbered">
<h3>Distribuciones muestrales y errores estándar</h3>
<div class="caja">
<p>La <strong>distribución muestral</strong> de una estadística es la distribución de
probabilidad de la misma, considerada como una variable aleatoria.</p>
</div>
<p>Es así que la distribución muestral depende de:
1) La distribución poblacional,<br />
2) la estadística que se está considerando,<br />
y 3) la muestra aleatoria: cómo se seleccionan las unidades de la muestra y
cuántas.</p>
<p>En teoría para obtener la distribución muestral uno seguiría los siguientes
pasos:</p>
<ul>
<li><p>Selecciona muestras de una población (todas las posibles o un número infinito
de muestras).</p></li>
<li><p>Calcula la estadística de interés para cada muestra.</p></li>
</ul>
<p>La distribución de la estadística es la distribución muestral.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(LaplacesDemon)
<span class="kw">library</span>(patchwork)
<span class="co"># En este ejemplo la población es una mezcla de normales</span>
pob_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data_frame</span>(<span class="dt">x =</span> <span class="dv">-15</span><span class="op">:</span><span class="dv">20</span>), <span class="kw">aes</span>(x)) <span class="op">+</span>
<span class="st">    </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnormm, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">p =</span> <span class="kw">c</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>), <span class="dt">mu =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">8</span>), 
        <span class="dt">sigma =</span> <span class="kw">c</span>(<span class="fl">3.5</span>, <span class="dv">3</span>)), <span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;mu&quot;</span>, <span class="dt">xintercept =</span> <span class="dv">5</span>), <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_colour_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&#39;mu&#39;</span> =<span class="st"> &#39;red&#39;</span>), <span class="dt">name =</span> <span class="st">&#39;&#39;</span>, 
        <span class="dt">labels =</span> <span class="kw">expression</span>(mu)) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">subtitle =</span> <span class="st">&quot;Población&quot;, color = &quot;&quot;)</span>

<span class="st">samples &lt;- data_frame(sample = 1:3) %&gt;% </span>
<span class="st">    mutate(</span>
<span class="st">        sims = rerun(3, rnormm(30, p = c(0.3, 0.7), mu = c(-2, 8), </span>
<span class="st">            sigma = c(3.5, 3))), </span>
<span class="st">        x_bar = map_dbl(sims, mean))</span>
<span class="st">muestras_plot &lt;- samples %&gt;% </span>
<span class="st">    unnest() %&gt;% </span>
<span class="st">    ggplot(aes(x = sims)) +</span>
<span class="st">        geom_histogram(binwidth = 2, alpha = 0.5, fill = &quot;</span>darkgray<span class="st">&quot;) +</span>
<span class="st">        geom_vline(xintercept = 5, color = &quot;</span>red<span class="st">&quot;, alpha = 0.5) +</span>
<span class="st">        geom_segment(aes(x = x_bar, xend = x_bar, y = 0, yend = 0.8), </span>
<span class="st">            color = &quot;</span>blue<span class="st">&quot;) +</span>
<span class="st">        xlim(-15, 20) +</span>
<span class="st">        facet_wrap(~ sample) +</span>
<span class="st">        geom_text(aes(x = x_bar, y = 0.95, label = &quot;</span><span class="kw">bar</span>(x)<span class="st">&quot;), parse = TRUE, </span>
<span class="st">            color = &quot;</span>blue<span class="st">&quot;, alpha = 0.2, hjust = 1) +</span>
<span class="st">        labs(x = &quot;&quot;, subtitle = &quot;</span>Muestras<span class="st">&quot;) </span>

<span class="st">samples_dist &lt;- data_frame(sample = 1:10000) %&gt;% </span>
<span class="st">    mutate(</span>
<span class="st">        sims = rerun(10000, rnormm(100, p = c(0.3, 0.7), mu = c(-2, 8), </span>
<span class="st">            sigma = c(3.5, 3))), </span>
<span class="st">        mu_hat = map_dbl(sims, mean))</span>
<span class="st">dist_muestral_plot &lt;- ggplot(samples_dist, aes(x = mu_hat)) +</span>
<span class="st">    geom_density(adjust = 2) +</span>
<span class="st">    labs(x = &quot;&quot;, subtitle = expression(&quot;</span>Distribución muestral de <span class="st">&quot;~hat(mu))) +</span>
<span class="st">    geom_vline(xintercept = 5, color = &quot;</span>red<span class="st">&quot;, alpha = 0.5)</span>

<span class="st">(pob_plot | plot_spacer()) / (muestras_plot | dist_muestral_plot) </span></code></pre>
<p><img src="imagenes/ideal_world.png" /></p>
<p>Para hacer inferencia necesitamos describir la forma de la distribución
muestral, es natural pensar en la desviación estándar pues es una medida de la
dispersión de la distribución de la estadística alrededor de su media:</p>
<div class="caja">
<p>El <strong>error estándar</strong> es la desviación estándar de la distribución muestral de
una estadística.</p>
</div>
<div id="ejemplo-el-error-estandar-de-una-media" class="section level4 unnumbered">
<h4>Ejemplo: el error estándar de una media</h4>
<p>Supongamos que <span class="math inline">\(x\)</span> es una variable aleatoria que toma valores en los reales con
distribución de probabilidad <span class="math inline">\(P\)</span>. Denotamos por <span class="math inline">\(\mu_P\)</span> y <span class="math inline">\(\sigma_P^2\)</span> la
media y varianza de <span class="math inline">\(P\)</span>,</p>
<p><span class="math display">\[\mu_P = E_P(x),\]</span>
<span class="math display">\[\sigma_P^2=var_P(x)=E_P[(x-\mu_P)^2]\]</span></p>
<p>en la notación enfatizamos la dependencia de la media y varianza en la
distribución <span class="math inline">\(P\)</span>.</p>
<p>Ahora, sea <span class="math inline">\((x_1,...,x_n)\)</span> una muestra aleatoria de <span class="math inline">\(P\)</span>, de tamaño <span class="math inline">\(n\)</span>,
la media de la muestra <span class="math inline">\(\bar{x}=\sum_{i=1}^nx_i/n\)</span> tiene:</p>
<ul>
<li><p>esperanza <span class="math inline">\(\mu_P\)</span>,</p></li>
<li><p>varianza <span class="math inline">\(\sigma_P^2/n\)</span>.</p></li>
</ul>
<p>En palabras: la esperanza de <span class="math inline">\(\bar{x}\)</span> es la misma que la esperanza de <span class="math inline">\(x\)</span>, pero
la varianza de <span class="math inline">\(\bar{x}\)</span> es <span class="math inline">\(1/n\)</span> veces la varianza de <span class="math inline">\(x\)</span>, así que entre
mayor es la <span class="math inline">\(n\)</span> tenemos una mejor estimación de <span class="math inline">\(\mu_P\)</span>.</p>
<p>En el caso de la media <span class="math inline">\(\bar{x}\)</span>, el error estándar, que denotamos
<span class="math inline">\(se_P(\bar{x})\)</span>, es la raíz de la varianza de <span class="math inline">\(\bar{x}\)</span>,</p>
<p><span class="math display">\[se_P(\bar{x}) = [var_P(\bar{x})]^{1/2}= \sigma_P/ \sqrt{n}.\]</span></p>
<p>En este punto podemos usar el principio del <em>plug-in</em>, simplemente sustituimos
<span class="math inline">\(P_n\)</span> por <span class="math inline">\(P\)</span> y obtenemos, primero, una estimación de <span class="math inline">\(\sigma_P\)</span>:
<span class="math display">\[\hat{\sigma}=\hat{\sigma}_{P_n} = \bigg\{\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2\bigg\}^{1/2}\]</span></p>
<p>de donde se sigue la estimación del error estándar:</p>
<p><span class="math display">\[\hat{se}(\bar{x})=\hat{\sigma}_{P_n}/\sqrt{n}=\bigg\{\frac{1}{n^2}\sum_{i=1}^n(x_i-\bar{x})^2\bigg\}^{1/2}\]</span></p>
<p>Notemos que usamos el principio del <em>plug-in</em> en dos ocasiones, primero para
estimar la esperanza <span class="math inline">\(\mu_P\)</span> mediante <span class="math inline">\(\mu_{P_n}\)</span> y luego para estimar el
error estándar <span class="math inline">\(se_P(\bar{x})\)</span>.</p>
<p><img src="imagenes/manicule2.jpg" /> Consideramos la base de datos <code>primaria</code>, y la
columna de calificaciones de español 3<sup>o</sup> de primaria (<code>esp_3</code>).</p>
<ul>
<li><p>Selecciona una muestra de tamaño <span class="math inline">\(n = 10, 100, 1000\)</span>. Para cada muestra
calcula media y el error estándar de la media usando el principio del <em>plug-in</em>:
<span class="math inline">\(\hat{\mu}=\bar{x}\)</span>, y <span class="math inline">\(\hat{se}(\bar{x})=\hat{\sigma}_{P_n}/\sqrt{n}\)</span>.</p></li>
<li>Ahora aproximareos la distribución muestral, para cada tamaño de muestra <span class="math inline">\(n\)</span>:</li>
</ul>
<ol style="list-style-type: lower-roman">
<li>simula 10,000 muestras aleatorias, ii) calcula la media en cada muestra, iii)
Realiza un histograma de la distribución muestral de las medias (las medias del
paso anterior) iv) aproxima el error estándar calculando la desviación estándar
de las medias del paso ii.</li>
</ol>
<ul>
<li><p>Calcula el error estándar de la media para cada tamaño de muestra usando la
información poblacional (ésta no es una aproximación), usa la fórmula:
<span class="math inline">\(se_P(\bar{x}) = \sigma_P/ \sqrt{n}\)</span>.</p></li>
<li><p>¿Cómo se comparan los errores estándar correspondientes a los distintos
tamaños de muestra?</p></li>
</ul>
</div>
<div id="por-que-bootstrap" class="section level4 unnumbered">
<h4>¿Por qué bootstrap?</h4>
<ul>
<li><p>En el caso de la media <span class="math inline">\(\hat{\theta}=\bar{x}\)</span> la aplicación del principio del
<em>plug-in</em> para el cálculo de errores estándar es inmediata; sin embargo, hay
estadísticas para las cuáles no es fácil aplicar este método.</p></li>
<li><p>El método de aproximarlo con simulación, como lo hicimos en el ejercicio de
arriba no es factible pues en la práctica no podemos seleccionar un número
arbitrario de muestras de la población, sino que tenemos únicamente una muestra.</p></li>
<li><p>La idea del <em>bootstrap</em> es replicar el método de simulación para aproximar
el error estándar, esto es seleccionar muchas muestras y calcular la estadística
de interés en cada una, con la diferencia que las muestras se seleccionan de la
distribución empírica a falta de la distribución poblacional.</p></li>
</ul>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bootstrap-no-parametrico.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="el-estimador-bootstrap-del-error-estandar.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tereom/est-computacional-2018/edit/master/05-bootstrap_no_parametrico.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["est-computacional-2018.pdf", "est-computacional-2018.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
